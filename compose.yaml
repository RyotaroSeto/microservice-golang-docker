services:
  service-1:
    container_name: service-1
    build:
      context: ./services/service-1
      dockerfile: Dockerfile
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      # KAFKA_GROUP_ID: test-group
      KAFKA_TOPIC: my-topic-1
    ports:
      - "8080:8080"
    volumes:
      - ./:/app:delegated
    depends_on:
      kafka:
        condition: service_healthy

  # service-2:
  #   container_name: service-2
  #   build:
  #     context: ./services/service-2
  #     dockerfile: Dockerfile
  #   ports:
  #     - "8081:8081"
  #   volumes:
  #     - ./:/app:delegated
  #   depends_on:
  #   - kafka

  zookeeper:
    container_name: zookeeper
    restart: always
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SERVER_ID: 1
    # volumes:
    #   - ./data/zookeeper/data:/data
    #   - ./data/zookeeper/datalog:/datalog

  kafka:
    container_name: kafka
    restart: always
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_SESSION_TIMEOUT: 6000
      KAFKA_RESTART_ATTEMPTS: 10
      KAFKA_RESTART_DELAY: 5
      KAFKA_BROKER_ID: 1
    # volumes:
    #   - ./data/kafka/data:/var/lib/kafka/data
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "cub", "kafka-ready", "-b", "kafka:29092", "1", "5"]
      interval: 5s
      timeout: 10s
      retries: 5

  init-topics:
    container_name: init-topics
    image: confluentinc/cp-kafka:7.3.2
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic my-topic-1 --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic my-topic-2 --replication-factor 1 --partitions 1

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:29092 --list
      "

  kafdrop:
    container_name: kafdrop
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
    depends_on:
      kafka:
        condition: service_healthy

  # etcd:
  #   container_name: etcd
  #   image: gcr.io/etcd-development/etcd:v3.4.7
  #   ports: ["12379:12379", "12380:12380"]
  #   command: >-
  #     /usr/local/bin/etcd
  #     -name etcd
  #     -data-dir /etcd-data
  #     -listen-client-urls http://0.0.0.0:12379
  #     -advertise-client-urls http://0.0.0.0:12379
  #     -listen-peer-urls http://0.0.0.0:12380
  #     -initial-advertise-peer-urls http://0.0.0.0:12380
  #     -initial-cluster etcd=http://0.0.0.0:12380
  #     -initial-cluster-token tkn
  #     -initial-cluster-state new
  #   networks:
  #     - services_network



  # redis:
  #   image: redis:6-alpine
  #   restart: always
  #   container_name: redis
  #   ports:
  #     - "6379:6379"
  #   networks:
  #     - services_network

  # redisinsight:
  #   container_name: redisinsight
  #   image: redislabs/redisinsight:latest
  #   ports:
  #     - 8001:8001
  #   volumes:
  #     - ./redisinsight:/db
  #   depends_on:
  #     - redis
  #   networks:
  #     - services_network
