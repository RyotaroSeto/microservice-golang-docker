services:
  service-1:
    container_name: service-1
    build:
      context: ./services/service-1
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    volumes:
      - ./:/app:delegated
    networks:
      - services_network

  service-2:
    container_name: service-2
    build:
      context: ./services/service-2
      dockerfile: Dockerfile
    ports:
      - "8081:8081"
    volumes:
      - ./:/app:delegated
    networks:
      - services_network

  zookeeper:
    container_name: zookeeper
    restart: always
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SERVER_ID: 1
    volumes:
      - ./data/zookeeper/data:/data
      - ./data/zookeeper/datalog:/datalog
    networks:
      - services_network

  kafka:
    container_name: kafka
    restart: always
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: "INTERNAL://:29092,EXTERNAL://:9092"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:29092,EXTERNAL://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_ZOOKEEPER_SESSION_TIMEOUT: "6000"
      KAFKA_RESTART_ATTEMPTS: "10"
      KAFKA_RESTART_DELAY: "5"
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
    volumes:
      - ./data/kafka/data:/var/lib/kafka/data
    depends_on:
      - zookeeper
    networks:
      - services_network

  kafdrop:
    container_name: kafdrop
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
    depends_on:
      - kafka
    networks:
      - services_network
networks:
  services_network:
    driver: bridge

  # etcd:
  #   container_name: etcd
  #   image: gcr.io/etcd-development/etcd:v3.4.7
  #   ports: ["12379:12379", "12380:12380"]
  #   command: >-
  #     /usr/local/bin/etcd
  #     -name etcd
  #     -data-dir /etcd-data
  #     -listen-client-urls http://0.0.0.0:12379
  #     -advertise-client-urls http://0.0.0.0:12379
  #     -listen-peer-urls http://0.0.0.0:12380
  #     -initial-advertise-peer-urls http://0.0.0.0:12380
  #     -initial-cluster etcd=http://0.0.0.0:12380
  #     -initial-cluster-token tkn
  #     -initial-cluster-state new
  #   networks:
  #     - services_network

  # kafka-init-topics:
  #   container_name: kafka-init-topics
  #   image: confluentinc/cp-kafka:7.3.2
  #   volumes:
  #      - ./message.json:/data/message.json
  #   depends_on:
  #     - kafka
  #   command: "cub kafka-ready -b kafka:29092 1 30 && \
  #             kafka-topics --create --topic second.users --partitions 3 --replication-factor 1 --if-not-exists --zookeeper zookeeper:2181 && \
  #             kafka-console-producer --broker-list kafka:29092 -topic second.users < /data/message.json'"
  #   networks:
  #     - services_network

  # redis:
  #   image: redis:6-alpine
  #   restart: always
  #   container_name: redis
  #   ports:
  #     - "6379:6379"
  #   networks:
  #     - services_network

  # redisinsight:
  #   container_name: redisinsight
  #   image: redislabs/redisinsight:latest
  #   ports:
  #     - 8001:8001
  #   volumes:
  #     - ./redisinsight:/db
  #   depends_on:
  #     - redis
  #   networks:
  #     - services_network
